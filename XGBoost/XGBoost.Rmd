---
title: "ENAR DataFest"
author: "Boyu Jiang"
date: "11/22/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Load data



```{r}
library(cardioStatsUSA)
raw_data <- nhanes_data[svy_subpop_htn == 1]

raw_data_htn <- raw_data[htn_escesh == 'Yes'] # 19377 rows

summary(raw_data_htn$bp_control_escesh_1)

selected_feature <- c('bp_control_escesh_1','demo_race','demo_age_years',"demo_pregnant","demo_gender","cc_smoke","cc_bmi","cc_diabetes","cc_ckd","cc_cvd_mi","cc_cvd_chd","cc_cvd_stroke","cc_cvd_ascvd","cc_cvd_hf","bp_med_n_pills","bp_med_ace","bp_med_aldo","bp_med_alpha","bp_med_angioten", "bp_med_beta","bp_med_central","bp_med_ccb","bp_med_ccb_dh","bp_med_ccb_ndh","bp_med_diur_Ksparing","bp_med_diur_loop", "bp_med_diur_thz","bp_med_renin_inhibitors","bp_med_vasod")

raw_data_htn <- subset(raw_data_htn, select = selected_feature)
```


Read from csv file.


```{r}
library(readr)
data_dummy_var <- read_csv("data_dummy var.csv")
```



Adults with hypertension = 19377

Among these adults, bp_control = 8454; no bp_control = 10923


Split the whole dataset into training set (80%) and testing set (20%).

```{r}
set.seed(7)
train_indices <- sample(1:nrow(data_dummy_var), round(0.8*nrow(data_dummy_var)))

# y = 'bp_control_escesh_1'


train <- data_dummy_var[train_indices, ]
# train <- subset(train, select = selected_feature)
train <- as.matrix(train)
#train_x <- subset(train, select = selected_feature)
#train_y <- train$

test <- data_dummy_var[-train_indices, ]
#test <- subset(test, select = selected_feature)
test <- as.matrix(test)
#test_x <- subset(test, select = selected_feature)
#test_y <- test$bp_control_escesh_1


```



# Cross Validation


Random search and 10-fold cross validation for the best combination of hyperparameters.


```{r warning=FALSE, error=FALSE, echo=FALSE, eval=FALSE}
set.seed(7)

# Import necessary libraries
library(xgboost)
library(caret)
library(magrittr)
library(dplyr)

# Split data into training and testing sets
#train_size <- floor(0.8 * nrow(rawdata))
#train <- rawdata[1:train_size, ]
#test <- rawdata[(train_size + 1):nrow(rawdata), ]


# 
hyper_grid <- expand.grid(
  eta = c(.01, .05, .1), 
  max_depth = c(3, 5, 7),
  min_child_weight = c(1, 3, 5),
  subsample = runif(n=2, min = 0, max = 1), 
  colsample_bytree = runif(n=3, min = 0, max = 1),
  optimal_trees = 0,               # a place to dump results
  min_error = 0                     # a place to dump results
)

print(hyper_grid) # 162 combination of hyperparameters
```



```{r echo=FALSE, eval=FALSE}
# grid search 
for(i in 1:nrow(hyper_grid)) {
    # create parameter list
  params <- list(
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i]
  )
  # train model
  xgb.tune <- xgb.cv(
    params = params,
    data = train[,-1],
    label = train[,1],
    nrounds = 500,
    nfold = 10,
    objective = "binary:logistic",  # for regression models
    verbose = 0,               # silent,
    early_stopping_rounds = 15, # stop if no improvement for 15 consecutive trees
    metrics='error'
    )
  
  # add min training error and trees to grid
  hyper_grid$optimal_trees[i] <- which.min(xgb.tune$evaluation_log$test_error_mean)
  hyper_grid$min_error[i] <- min(xgb.tune$evaluation_log$test_error_mean)
}
```



# Train the best model



```{r echo=FALSE, warning=FALSE, error=FALSE,}
# train best model
set.seed(7)
# Import necessary libraries
library(xgboost)
#library(caret)
#library(magrittr)
#library(dplyr)


params <- list(
  eta = 0.1,
  max_depth = 5,
  min_child_weight = 3,
  subsample = 0.98,
  colsample_bytree = 0.24
)


xgb.best <- xgboost(
  params = params,
  data = train[,-1],
  label = train[,1],
  nrounds = 500,
  objective = "binary:logistic",
  verbose = 0
)
```


Importance ranking - top 10


```{r}
# create importance matrix
importance_matrix <- xgb.importance(model = xgb.best)


# variable importance plot
par(mar = c(4, 38, 2, 3))
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", xlab = "Gain", main = "Variable Importance")
```

Partial Dependence Plots (PDPs): PDPs visualize the marginal effect of a single feature on the model's predictions, holding other features constant. These plots help understand how the model's predictions change as the value of a particular feature increases or decreases.


```{r}
# Make Partial Dependence Plots for xgb.best
# 
library(pdp)
p <- partial(object = xgb.best, pred.var = c("bp_med_ace","demo_age_years", "bp_med_n_pills"), train = train[,-1])
plot(p)
```



# Make prediction



```{r echo=FALSE, fig.cap='Training and validation results of best XGBoost model.'}
# plot the test prediction results
result_forecast = data.frame(real = test[,1], forecast = predict(xgb.best, test[,-1]))

library(pROC)
roc_curve <- roc(response = result_forecast$real, predictor = result_forecast$forecast, plot = TRUE)
# plot(roc_curve, main="ROC Curve", col="blue")
auc(roc_curve)

```

